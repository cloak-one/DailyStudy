# 数学建模——建模篇

## 分类与建模方法总述

<img src="https://s2.loli.net/2024/07/25/UWMt3PkmznAOq8s.png" alt="image-20240723103141662" />

## 评价决策类赛题

### 建模步骤

![image-20240724180037303](https://s2.loli.net/2024/07/25/7UjrP6k8OnS3cwZ.png)

### 客观评价问题的区别

- 主客观概念主要是在指标定权时来划分的。主观评价与客观评价的区别是，主观评价算法在定权时主要以判断者的主观经验为依据，而客观评价则主要基于测量数据的基本特性来综合定权
- 定权带有一定的主观性，用不同方法确定的权重分配，可能不尽一致，这将导致权重分配的不确定性，最终可能导致评价结果的不确定性。因而在实际工作中，不论用哪种方法确定权重分配，都应当依赖于较为合理的专业解释。

###  选择方法

![image-20240723232459187](https://s2.loli.net/2024/07/25/2swGBvmRYJu9zK8.png)

1. **层次分析法**

基本思想：是定性与定量相结合的多准则决策、评价方法。将决策的有关元素分解成目标层、准则层和方案层，并通过人们的判断对决策方案的优劣进行排序，在此基础上进行定性和定量分析。它把人的思维过程层次化、数量化，并用数学为分析、决策、评价、预报和控制提供定量的依据。

基本步骤：构建层次结构模型；构建成对比较矩阵；层次单排序及一致性检验（即判断主观构建的成对比较矩阵在整体上是否有较好的一致性）；层次总排序及一致性检验（检验层次之间的一致性）。

优点：它完全依靠主观评价做出方案的优劣排序，所需数据量少，决策花费的时间很短。从整体上看，AHP在复杂决策过程中引入定量分析，并充分利用决策者在两两比较中给出的偏好信息进行分析与决策支持，既有效地吸收了定性分析的结果，又发挥了定量分析的优势，从而使决策过程具有很强的条理性和科学性，特别适合在社会经济系统的决策分析中使用

缺点：用AHP进行决策<u>主观</u>成分很大。当决策者的判断过多地受其主观偏好影响，而产生某种对客观规律的歪曲时，AHP的结果显然就靠不住了

适用范围：尤其适合于人的定性判断起重要作用的、对决策结果难于直接准确计量的场合。要使AHP的决策结论尽可能符合客观规律，决策者必须对所面临的问题有比较深入和全面的认识。另外，当遇到因素众多，规模较大的评价问题时，该模型容易出现问题，它要求评价者对问题的本质、包含的要素及其相互之间的逻辑关系能掌握得十分透彻，否则评价结果就不可靠和准确

改进方法：（1）成对比较矩阵可以采用德尔菲法获得。（2）如果评价指标个数过多（一般超过9个），利用层次分析法所得到的权重就有一定的偏差，继而组合评价模型的结果就不再可靠。可以根据评价对象的实际情况和特点，利用一定的方法，将各原始指标分层和归类，使得每层各类中的指标数少于9个

2. **灰色综合评价法（灰色关联度分析)**

基本思想：灰色关联分析的实质就是，可利用各方案与最优方案之间关联度大小对评价对象进行比较、排序。关联度越大，说明比较序列与参考序列变化的态势越一致，反之，变化态势则相悖。由此可得出评价结果。

基本步骤：建立原始指标矩阵；确定最优指标序列；进行指标标准化或无量纲化处理；求差序列、最大差和最小差；计算关联系数；计算关联度。

优点：是一种评价具有大量未知信息的系统的有效模型，是定性分析和定量分析相结合的综合评价模型，该模型可以较好地解决评价指标难以准确量化和统计的问题，可以排除人为因素带来的影响，使评价结果更加<u>客观</u>准确。整个计算过程简单、通俗易懂，易于为人们所掌握数据不必进行归一化处理，可用原始数据进行直接计算，可靠性强；评价指标体系可以根据具体情况增减；无需大量样本，只要有代表性的少量样本即可。

缺点：要求样本数据且具有时间序列特性；只是对评判对象的优劣做出鉴别，并不反映绝对水平，故基于灰色关联分析综合评价具有“相对评价”的全部缺点。

适用范围：对样本量没有严格要求，不要求服从任何分布，适合只有少量观测数据的问题；应用该种方法进行评价时，指标体系及权重分配是一个关键的题，选择的恰当与否直接影响最终评价结果。

改进方法：*采用组合赋权法*：根据客观赋权法和主观赋权法综合而得权系数。（2）结合TOPSIS法：不仅关注序列与正理想序列的关联度，而且关注序列与负理想序列的关联度，依据公式计算最后的关联度

**关联分析步骤**

1、母序列(又称参考序列、母指标)：能反映系统行为特征的数据序列，类似于因变量 Y ,记为

$Y=\begin{bmatrix}y_1,y_2,\cdots,y_n\end{bmatrix}^T$

2、子序列(又称比较序列、子指标)：影响系统行为的因素组成的数据序列，类似于自变量X，记为

$$\begin{aligned}&X_{nm}=\begin{bmatrix}x_{11}&x_{12}&\cdots&x_{1m}\\x_{21}&x_{22}&\cdots&x_{2m}\\\vdots&\vdots&\ddots&\vdots\\x_{n1}&x_{n2}&\cdots&x_{nm}\end{bmatrix}\\&\end{aligned}$$

3、数据预处理：由于不同要素具有不同量纲和数据范围，因此我们要对他们进行预处理去量纲，将他们统一到近似的范围内，先求出每个指标的均值，在用指标中的元素除以其均值

$$\widetilde{y_{k}}=\frac{y_{k}}{\overline{y_{i}}},\overline{y_{i}}=\frac{1}{n}\sum_{k=1}^{n}y_{k}\quad\widetilde{x_{ki}}=\frac{x_{ki}}{\overline{x_{i}}},\overline{x_{i}}=\frac{1}{n}\sum_{k=1}^{n}x_{ki}\left(i=1,2,\cdots,m\right)$$

4、计算灰色关联系数：计算子序列中各个指标与母序列的关联系数，记为：

$ a= min_i\min _k\left | x_0\left ( k\right ) - x_i\left ( k\right ) \right | , \quad b= max_i \max _k \left | x_o\left ( k\right ) - x_i\left ( k\right ) \right |$ 为两极最小差和最大差

构造：$\xi_i(k) = y(x_0(k),x_i(k)) = \frac{a + \rho b}{\left |x_0(k)-x_i(k)\right|+ \rho b}$ 其中 $\rho  $ 为分辨系数，一般取0.5

5、计算关联度

$$r_i = \frac{1}{n}\sum_{k=1}^n \xi_i(k) = \frac{1}{n}\sum_{k=1}^ny(x_0(k),x_i(k))$$

3. **模糊综合评价法**

基本思想：是以模糊数学为基础，应用模糊关系合成的原理，将一些边界不清、不易定量的因素定量化，从多个因素对被评价事物隶属等级（或称为评语集）状况进行综合性评价的一种方法。综合评判对评判对象的全体，根据所给的条件，给每个对象赋予一个非负实数评判指标，再据此排序择优。<u>模糊综合评价模型就是给定对象，用因素集的指标进行评价，从评语集中找到一个最适合它的评语</u>

基本步骤：确定因素集、评语集；构造模糊关系矩阵：确定指标权重；进行模糊合成和做出评价。

优点：数学模型简单，容易掌握，对多因素、多层次的复杂问题评判效果较好。模糊评价模型不仅可对评价对象按综合分值的大小进行评价和排序，而且还可根据模糊评价集上的值按最大隶属度原则去评定对象所属的等级，结果包含的信息量丰富。评判逐对进行，对被评对象有唯一的评价值，不受被评价对象所处对象集合的影响。接近于东方人的思维习惯和描述方法，因此它更适用于<u>对社会经济系统问题</u>进行评价。

缺点：并不能解决评价指标间相关造成的评价信息重复问题，隶属函数的确定还没有系统的方法，而且合成的算法也有待进一步探讨。其评价过程大量运用了人的主观判断，由于各因素权重的确定带有一定的<u>主观性</u>，因此，总的来说，模糊综合评判是一种基于主观信息的综合评价方法。

应用范围：广泛地应用于经济管理等领域。综合评价结果的可靠性和准确性依赖于指标选取因素、因素的权重分配和综合评价的合成算子等。

改进方法：*采用组合赋权法*：根据客观赋权法和主观赋权法综合而得权重系数。

模糊集合的分类：

- 模糊集合主要有三类，分别为偏小型，中间型和偏大型。其实也就类似于TOPSIS方法中的极大
  型、极小型、中间型、区间型指标。

隶属函数的确定方法：

1）模糊统计法

模糊统计法的原理是，找多个人对同一个模糊概念进行描述，用隶属频率去定义隶属度。

例如我们想知道30岁相对于“年轻”的隶属度，那就找来n个人问一问，如果其中有m个人认为30岁属于“年轻”的范畴，那m/n就可以用来作为30岁相对于“年轻”的隶属度。n越大时，越符合实际情况，也就越准确。

这个方法比较符合实际情况，但是往往通过发放问卷或者其他手段进行调查，数学建模比赛时，时间有限，所以仅做介绍，基本不予采用。

2）借助已有的客观尺度

对于某些模糊集合，我们可以用已经有的指标去作为元素的隶属度。

注意：隶属度是在[0,1]之间的。如果找的指标不在，可以进行归一化处理。

![image-20240811185143057](https://s2.loli.net/2024/08/12/wCPArYJRlQjcfkh.png)

模糊评价问题是要把论域中的对象对应评语集中一个指定的评语或者将方案作为评语集并选择一个最优的方案。

①因素集（评价指标集）$U=\{u_1,u_2...,u_n\}$
②评语集（评价的结果）$V = \{v_1,v_2,\dots,v_n\}$
③权重集（指标的权重）$A = \{a_1,a_2,\dots,a_n\}$

**一级模糊综合评价模型**：在指标个数较少的考核中，可以运用一级模糊综合评判。

1）确定因素集：评判的因素构成的评价指标体系集合称为因素集

2）确定评语集：由各种不同决断构成的集合称为评语集

3）确定各因素的权重：因素集中各因素的评价中作用不同，需要确定权重，它是U上的模糊向量判断权重的方法很多，如Delphi法等，也可以用我们学习过的层次分析法和熵权法来确定权重。记为  $A=[a_1,a_2,…,a_n]$

**多层次模糊综合评价模型**

1）给出被评价的对象集合  $X=\left\{x_{1}, x_{2}, \ldots, x_{k}\right\}$ 

2）攻定固素集(亦称指标体系)  $U=\left\{u_{1}, u_{2}, \ldots, u_{n}\right\}$ 

​	若因素众多, 往往将  $U=\left\{u_{1}, u_{2}, \ldots, u_{n}\right\}$  按某些属性分成 s 个子集  $U_{i}=\left\{u_{1}^{(i)}, u_{2}^{(i)}, \ldots, u_{n_{i}}^{(i)}\right\}, i=1,2, \ldots, s $ 且满足条件:

$\quad (1)  \sum_{\mathrm{i}=1}^{s} n_{i}=n ;
 \quad (2)  \bigcup_{i=1}^{s} U_i=U ;
 \quad (3)  U_i {\bigcap} U_{j}=\phi, i \neq j $

3）确定评语集  $V=\left\{v_{1}, v_{2}, \ldots, v_{m}\right\}$ 

4）由因素集  $U_{i}$  与评语集  V , 可获得一个评价矩阵

$R_{i}=\left[\begin{array}{cccc}
r_{11}^{(i)} & r_{12}^{(i)} & \ldots & r_{1 m}^{(i)} \\
\vdots & \vdots & \vdots & \vdots \\
r_{n_{i} 1}^{(i)} & r_{n_{i} 2}^{(i)} & \ldots & r_{n_{i} m}^{(i)}
\end{array}\right]$

5）对每一个  $U_{i}$ , 分别作出综合决策。

设  $U_{i}$  中的各因素权重的分配（模糊权向量）为  $A_{i}=\left(a_{1}^{(i)}, a_{2}^{(i)} \ldots, a_{n_{i}}^{(i)}\right)$  ，其中  $\sum_{t=1}^{n_{i}} a_{t}^{(i)}=1$  。若  $R_{i}$  为单因素模糊判断矩阵, 则得到一级评价向量为:

$B_{i}=A_{i} \cdot R_{i}=\left(b_{i 1}, b_{i 2}, \ldots, b_{i m}\right), \quad i=1,2, \ldots, s$

6 ) 将每个  $U_{i}$  视为一个元素, 记  $U=\left\{U_{1}, U_{2}, \ldots, U_{s}\right\}$ , 于是  U  又是单因素集,  U  的单因素判断矩阵为

$R=\left[\begin{array}{l}
B_{1} \\
B_{2} \\
\vdots \\
B_{s}
\end{array}\right]=\left[\begin{array}{cccc}
b_{11} & b_{12} & \cdots & b_{1 m} \\
\vdots & \vdots & \vdots & \vdots \\
\vdots & \vdots & \vdots & \vdots \\
b_{s 1} & b_{s 2} & \cdots & b_{s m}
\end{array}\right]$

每个  $U_{i}$  作为  U  的一部分，反映了  U  的某种属性，可以按他们的重要性给出权重分配

$A=\left(a_{1}, a_{2}, \ldots, a_{s}\right)$


于是得到二级模糊综合评价模型为:	$B=A \cdot R=\left(b_{1}, b_{2}, \ldots, b_{m}\right)$


若每个子因素  $U_{i}(i=1,2, \ldots, s)$  仍有较多因素, 则可将  $U_{i}$  再划分, 于是有三级或更高级模型

4. **BP神经网络综合评价法**

基本思想：是一种交互式的评价方法，它可以根据用户期望的输出不断修改指标的权值，直到用户满意为止。因此，一般来说，人工神经网络评价方法得到的结果会更符合实际情况。

优点：神经网络具有自适应能力，能对多指标综合评价问题给出一个<u>客观评价</u>，这对于弱化权重确定中的人为因素是十分有益的。在以前的评价方法中，传统的权重设计带有很大的模糊性，同时权重确定中人为因素影响也很大。随着时间、空间的推移，各指标对其对应题的影响程度也可能发生变化，确定的初始权重不一定符合实际情况。再者，考虑到整个分析评价是一个复杂的非线性大系统，必须建立权重的学习机制，这些方面正是人工神经网络的优势所在。针对综合评价建模过程中变量选取方法的局限性，采用神经网络原理可对变量进行贡献分析，进而剔除影响不显著和不重要的因素，以建立简化模型，可以避免主观因素对变量选取的干扰。

缺点：ANN在应用中遇到的最大问题是不能提供解析表达式，权值不能解释为一种回归系数，也不能用来分析因果关系，目前还不能从理论上或从实际出发来解释ANN的权值的意义。需要大量的训练样本，精度不高，应用范围是有限的。最大的应用障碍是评价算法的复杂性，人们只能借助计算机进行处理，而这方面的商品化软件还不够成熟。

适用范围：神经网络评价模型具有自适应能力、可容错性，能够处理非线性、非局域性的大型复杂系统。在对学习样本训练中，无需考虑输入因子之间的权系数，ANN通过输入值与期望值之间的误差比较，沿原连接权自动地进行调节和适应，因此该方法体现了因子之间的相互作用。

改进方法：*采用组合评价法*：对用其它评价方法得出的结果，选取一部分作为训练样本，一部分作为待测样本进行检验，如此对神经网络进行训练，知道满足要求为止，可得到更好的效果。

5. **Topsis**

基本思想：TOPSIS法是一种常用的综合评价方法，能充分利用原始数据的信息，其结果能精确地反映各评价方案之间的差距。

基本概念：<u>理想解</u>：设想的最优的解(方案)，它的各个属性值都达到各备选方案中的最好的值；<u>负理想解</u>：设想的最劣的解(方案)，它的各个属性值都达到各备选方案中的最坏的值。

方案排序的规则是把各备选方案与理想解和负理想解做订比较，若其中有一个方案最接近理想解，而同时又远离负理想解，则该方案是备选方案中最好的方案。TOPSIS通过最接近理想解且最远离负理想解来确定最优选择。

基本步骤：

1）将原始矩阵正向化，将所有的指标类型转化为<u>极大型指标</u>

![image-20240807112520098](https://s2.loli.net/2024/08/12/DyXGB6Z7tHkMdfY.png)

2）正向化矩阵标准化	标准化的目的是<u>消除不同指标量纲的影响</u>

<img src="https://s2.loli.net/2024/08/12/PquYrWShsKyHTJ9.png" alt="image-20240807113716058" style="zoom:80%;" />

*标准化*后，还需给不同指标加上权重，采用的权重确定方法有层次分析法、熵权法、Delphi法、对数最小二乘法等。

3）计算得分并归一化

![image-20240807114418460](https://s2.loli.net/2024/08/12/F4HV5MDbLfanrtj.png)

6. **熵权法**

基本思想：熵权法，物理学名词，按照信息论基本原理的解释，信息是系统有序程度的一个度量，熵是系统无序程度的一个度量；根据信息炳的定义，对于某项指标，可以用熵值来判断某个指标的离散程度，其信息熵值越小，指标的离散程度越大，该指标对综合评价的影响（即权重）就越大，如果某项指标的值全部相等，则该指标在综合评价中不起作用。因此，可利用信息熵这个工具，计算出各个指标的权重，为多指标综合评价提供依据。

熵权法是一种客观的赋权方法，它可以靠数据本身得出权重。

依据的原理：指标的变异程度越小，所反映的信息量也越少，其对应的权值也应该越低。

基本步骤：

- 数据标准化

  - 对标准化的矩阵记为Z，则 $z_{ij} = \frac{x_{ij}}{\sqrt{\sum^n_{i=1} x^2_{ij}}}$ 	如果 $x_{ij}$ 存在负数，则标准矩阵

  $$
  \tilde{Z}=\frac{x-\min \left\{x_{1 j}, x_{2 j}, \ldots, x_{n j}\right\}}{\max \left\{x_{1 j}, x_{2 j}, \ldots, x_{n j}\right\}-\min \left\{x_{1 j}, x_{2 j}, \ldots, x_{n j}\right\}}
  $$

    

- 计算概率矩阵P：计算第 j 项指标下第 i 个样本所占比重 
  $$
  p_{ij} = \frac{\tilde{z}_{ij}}{\sum^{m}_{j=1}\tilde{z}_{ij}}
  $$
  
- 计算熵权 $e_j = - \frac{1}{\ln n}\sum^n_{i=1}p_{ij}\ln (p_{ij})\ (j = 1,2,\dots,m) \quad d_j=1-e_j \quad W_j = \frac{d_j}{\sum^n_{j=1} d_j}$

7. **主成分分析法**

1）主成分分析方法

主成分分析是对于原先提出的所有变量，将重复的变量（关系紧密的变量）删去多余，建立尽可能少的新变量，使得这些新变量是两两不相关的，且这些新变量在反映课题的信息方面尽可能保持原有的信息。**设法将原来变量重新组合成一组新的互相无关的几个综合变量，同时根据实际需要从中可以取出几个较少的综合变量尽可能多地反映原来变量的信息的统计方法叫做主成分分析或称主分量分析**，也是数学上用来**降维**的一种方法。

2）数据降维

降维是将高维度的数据（指标太多）保留下最重要的一些特征，去除噪声和不重要的特征，从而实现提升数据处理速度的目的。

实际的生产和应用中，降维在一定的信息损失范围内，可以为我们节省大量的时间和成本。降维也成为应用非常广泛的数据预处理方法。

降维具有如下一些优点：（1）使得数据集更易使用（2）除噪声（3）降低算法的计算开销（4）使得结果容易理解

基本思想：PCA的主要目标是将特征维度变小，同时尽量减少信息损失。就是对一个样本矩阵，**一是换特征**，
找一组新的特征来重新标识；**二是减少特征**，新特征的数目要远小于原特征的数目。

<img src="https://s2.loli.net/2024/08/12/LQAIomti8HbTDCM.png" alt="image-20240812223054162" style="zoom:100%;" />

基本原理：通过PCA将n维原始特征映射到k维（k<n）上，称这 k 维特征为主成分）需要强调的是，不是简单地从n维特征中去除其余n一k维特征，而是重新构造出全新的 k 维正交特征，且新生成的k维数据尽可能多地包含原来n维数据的信息。例如，使用PCA将20个相关的特征转化为5个无关的新特征，并且尽可能保留原始数据集的信息。

**降维的代数意义可以理解为 m x n阶的原始样本 X ，与 n × k 阶矩阵 W 做矩阵乘法运算 X × W，即得到 m × R阶低维矩阵Y，这里的 n × k阶矩阵W就是投影矩阵。**

基本步骤：假设有n个样本，p个指标，则可构成大小为n×p的样本矩阵x :

$$x=\begin{bmatrix}x_{11}&x_{12}&\cdots&x_{1p}\\x_{21}&x_{22}&\cdots&x_{2p}\\\vdots&\vdots&\ddots&\vdots\\x_{n1}&x_{n2}&\cdots&x_{np}\end{bmatrix}=\begin{pmatrix}x_{1},x_{2},\cdots,x_{p}\end{pmatrix}$$

1）我们首先对其进行标准化处理：

按列计算均值$\overline x_j=\frac1n\sum_{i=1}^nx_{ij}$ 和标准差$S_j=\sqrt\frac{\sum_{i=1}^n(x_{ij}-\overline{x_j})^2}{n-1}$,计算得标准化数据$X_{ij}=\frac{x_{ij}-\overline{x_j}}{s_j}$

原始样本矩阵经过标准化变为：

$$X=\begin{bmatrix}X_{11}&X_{12}&\cdots&X_{1p}\\X_{21}&X_{22}&\cdots&X_{2p}\\\vdots&\vdots&\ddots&\vdots\\X_{n1}&X_{n2}&\cdots&X_{np}\end{bmatrix}=\begin{pmatrix}X_1,X_2,\cdots,X_p\end{pmatrix}$$

2）计算标准化样本的**协方差矩阵/样本相关系数矩阵**

$R= \begin{bmatrix} r_{11}& r_{12}& \cdots & r_{1p}\\ r_{21}& r_{22}& \cdots & r_{2p}\\ \vdots & \vdots & \ddots & \vdots \\ r_{n1}& r_{n2}& \cdots & r_{ip}\end{bmatrix}$ 其中   $r_{ij}=\frac1{n-1}\sum_{k=1}^{n}\left(X_{ki}-\overline{X_{i}}\right)\left(X_{kj}-\overline{X_{j}}\right)$

3）计算$R$的**特征值和特征向量**

特征值：$\lambda_1\geq\lambda_2\geq\ldots\geq\lambda_p\geq0$
特征向量：$a_1=\begin{bmatrix}a_{11}\\a_{21}\\\vdots\\a_{p1}\end{bmatrix},a_2=\begin{bmatrix}a_{12}\\a_{22}\\\vdots\\a_{p2}\end{bmatrix},\ldots,a_p=\begin{bmatrix}a_{1p}\\a_{2p}\\\vdots\\a_{pp}\end{bmatrix}$

4）计算主成分**贡献率以及累计贡献率**

贡献率 $\alpha_i = \frac{\lambda_i }{\sum^p_{k=1} \lambda_{k}}(i = 1,2 , \dots,p)$  累计贡献率 $\sum G = \frac{\sum ^i _{k-1}\lambda_i }{\sum^p_{k=1} \lambda_{k}}(i = 1,2 , \dots,p) $

5）写出主成分

一般取累计贡献率超过80%的特征值所对应的第一、第二、…、第m（m≤p)个主成分。

第 i 个主成分：$F=a_{1i}X1+a_{2i}X2+…+a_{pi}X_p(i=1,2,…,m)$

6）根据系数分析主成分代表的意义

对于某个主成分而言，指标前面的系数越大，代表该指标对于该主成分的影响越大

7）利用主成分的结果进行后续的分析

- 主成分得分
- 聚类分析

- 回归分析

总结：

**主成分的解释其含义一般多少带有点模糊性，不像原始变量的含义那么清楚、确切，这是变量**
**降维过程中不得不付出的代价**。

**主成分分析的困难之处主要在于要能够给出主成分的较好解释，所提取的主成分中如有一个主**
**成分解释不了，整个主成分分析也就失败了**。

## 控制预测类赛题

### 建模步骤

![image-20240724180351922](https://s2.loli.net/2024/07/25/6luQLmXvZYMJdzB.png)

### 预测类问题的区别

- 一类是无法用数学语言刻画其内部演化机理的问题
  - 基于过去的数据发现规律进行预测，称为数据预测
- 另一类是可以通过微分方程刻画其内部规律，这类问题我们称为机理建模问题通过微分方程建模求解

### 时间序列介绍

一个时间序列Y通常由长期趋势，季节变动，循环波动，不规则波动几部分组成：

- 长期趋势T指现象在较长时期内持续发展变化的一种趋向或状态，通常表现为一条光滑曲线趋势线。
- 季节波动S是由于季节的变化引起的现象发展水平的规则变动，通常可以表现为周期相对短一些的周期曲线。
- 循环波动I指在某段时间内，不具严格规则的周期性连续变动，通常表现为周期更长的周期曲线。
- 不规则波动C也可以叫噪声指由于众多偶然因素对时间序列造成的影响。

### 选择方法

![image-20240725102749896](https://s2.loli.net/2024/07/26/18pthLYUoIHAjnN.png)

1. **灰色预测**

基本思想：灰色预测是一种对含有不确定因素的系统进行预测的方法。灰色预测通过鉴别系统因素之间发展趋势的相异程度，即进行关联分析，并对原始数据进行生成处理来寻找系统变动的规律，生成有较强规律性的数据序列，然后建立相应的微分方程模型，从而预测事物未来发展趋势的状况。其用等时距观测到的反映预测对象特征的一系列数量值构造灰色预测模型，预测未来某一时刻的特征量，或达到某一特征量的时间。

基本步骤：1）数据检验与处理，判断数据列的级比是否都落在可容覆盖内，从而判断已知该数据列是否可进行灰色预测；2）根据预测算法建立灰色模型得到预测值；3）检验预测值----残差检验、级比偏差值检验；4）给出预测预报即结论。（开始一定要有级比检验）

优点：在<u>处理较少的特征值数据</u>，不需要数据的样本空间足够大，就能解诀历史数据少、序列的完整性以及可靠性低的问题，能将无规律的原始数据进行生成得到规律较强的生成序列。

缺点：只适用于中短期的预测，只适合近似于指数增长的预测。

适用范围：该模型使用的不是原始数据的序列，而是生成的数据序列。核心体系是Grey ModeI.即对原始数据作累加生成(或其他处理生成)得到近似的指数规律再进行建模的方法。

2. **回归预测方法**

基本思想：回归预测方法是根据自变量和因变量之间的相关关系进行预测的。自变量的个数可以一个或多个，根据自变量的个数可分为一元回归预测和多元回归预测。同时根据自变量和因变量的相关关系，分为线性回归预测方法和非线性回归方法。回归问题的学习等价于函数拟合：选择一条函数曲线使其很好的拟合已知数据且能很好的预测未知数据。

优点：1）回归分析法在分析多因素模型时，更加简单和方便；2）运用回归模型只要采用的模型和数据相同，通过标准的统计方法可以计算出唯一的结果，但在图和表的形式中，数据之间关系的解释往往因人而异，不同分析者画出的拟合曲线很可能也是不一样的；3）回归分析可以准确地计量各个因素之间的相关程度与回归拟合程度的高低，提高预测方程式的效果；

缺点：有时候在回归分析中，选用何种因子和该因子采用何种表达式只是一种推测，这影响了因子的多样性和某些因子的不可测性，使得回归分析在某些情况下受到限制；

适用范围：回归分析适合自变量和因变量之间具有一定的**相关关系**，并且该关系可以通过线性和非线性函数进行拟合

3. **时间序列分析法**

基本思想：ARIMA模型的全称叫做自回归移动平均模型，全称是（ARIMA，, Autoregressive Integrated Moving Average Model)也记作ARIMA（p，d，a），是统计模型（statistic model）中最常见的一种用来进行时间序列预测的模型。

建模流程：1）导入实验数据。2)确定ARMA模型阶数。3)残差检验。4)给出结果

适用范围：根据客观事物发展的这种连续规律性，运用过去的历史数据，通过统计分析，进一步推测市场未来的发展趋势。时间序列，在时间序列分析预测法处于核心位置。

优点：一般用ARMA模型拟合时间序列，预测该时间序列未来值。DanieI检验平稳性。自动回归AR（Autoregressive）和移动平均MA（MovingAverage）预测模型，“预测精度相对较高，<u>适合中长期预测问题</u>

缺点：当遇到外界发生较大变化，往往会有较大偏差，时间序列预测法对于中短期预测的效果要比长期预测的效果好。

4. **微分方程**

基本思想：微分方程模型是我们在日常生活中比较常见并且比较重要的一种模型，我们在平时的课程中时经常会涉及到这种题型，像比如我们所遇到的牛顿第二定律就常遇到相关的问题。

微分方程模型步骤：1）确定实际的量（所有要求的自变量、未知函数、必要参数）并确定坐标系。2）找出这些量所存在的基本关系（物理、化学，生物、几何等关系）。3）运用这些关系列出方程和定解条件。

优点：是短、中、长期的预测都适合。如传染病的预测模型、经济增长（或人口）的预测模型、Lanchester战争预测模型

缺点：反应事物内部规律及其内在关系，但由于方程的建立是以局部规律的独立性假定为基础，当作为长期预测时，误差较大，且微分方程的解比较难以得到

适用范围：适用于基于相关原理的因果预测模型，大多是<u>物理或几何方面</u>的典型问题，假设条件，用数学符号表示规律，列出方程，求解的结果就是问题的答案。

5. **移动平均法**

移动平均法是一种简单平滑预测技术，它的基本思想是：根据时间序列资料、逐项推移，依次计算包含一定项数的序列平均值，以反映长期趋势的方法。因此，当时间序列的数值由于受周期变动和随机波动的影响，起伏较大，不易显示出事件的发展趋势时，使用移动平均法可以消除这些因素的影响，显示出事件的发展方向与趋势（即趋势线），然后依趋势线分析预测序列的长期趋势。**移动平均法适用于短期预测**。

移动平均法根据预测时使用的各元素的权重不同，可以分为：*简单移动平均*和*加权移动平均*。

## 运筹优化类赛题

### 建模步骤

![image-20240726170749224](https://s2.loli.net/2024/07/26/GsZEuqVfBTzv3R1.png)

### 选择方法

![image-20240725113057759](https://s2.loli.net/2024/07/26/mgjS7sEFcMhYoQe.png)

**基于梯度的求解算法**：在无约束优化模型中，如果其目标函数为凸函数且可导，我们可以考虑通过梯度下降法求解其精确解，随机设定初始解，每次都沿梯度方向进行迭代，直到导数取值足够小。

因为梯度方向即为目标函数下降最快的方向，因此梯度下降算法求解速度很快，且精度很高，但<u>容易陷入局部最优解</u>，不能求解非凸问题。

<img src="https://s2.loli.net/2024/07/26/Wac9hItX2seyrqK.png" alt="image-20240725112538865" style="zoom:130%;" />

牛顿迭代法利用了二阶导数信息，迭代速度比梯度下降算法更多，对于强凸函数一次迭代即可找到最优解，但每欲迭代需要计算二阶Hesse矩阵，计算量相对较大

**启发式搜索算法**：上文介绍了所有求解算法都是面向凸优化的问题，所谓凸优化问题是指自标函数为凸函数且可行域为凸集，通俗来讲，就是目标函数在可行域范围内只有一个极值点，而非凸函数在可行域内存在无数个极值点，为了跳出局部最优解，找到全局最优解，人们开始了对启发式搜索算法的研究。

1. **粒子群优化算法**（ParticleSwarm Optimization，简称PS0），它源于对鸟群捕食行为的研究。粒子群优化算法的基本核心是利用群体中的个体对信息的共享，从而使得整个群体的运动在问题求解空间中产生从无序到有序的演化过程，从而获得问题的最优解。粒子群算法多用于<u>决策变量为连续变量</u>的优化问题，(其收敛速度快，但其跳出局部最优解的能力相对较弱。
2. **遗传算法**（GeneticAlgorithm）是模拟生物进化论的自然选择和遗传学机理的生物进化过程的计算模型，是一种通过模拟自然进化过程搜索最优解的方法。其主要用于决策变量为离散变量的优化问题，比如整数规划、0-1规划等。其收敛速度相对较慢，，但跳出局部最优解的能力较强。
3. **模拟退火算法**脱胎于自然界的物理过程，来源于固体退火原理，是一种基于概率的算法，将固体加温至充分高，再让其徐徐冷却，加温时，固体内部粒子随温升变为无序状，内能增大，而徐徐冷却时粒子渐趋有序，在每个温度都达到平衡态，最后在常温时达到基态，内能减为最小。
   - 模拟退火算法相对来说，对决策变量类型没有约束，不管是连续变量还是离散变量都可以进行求解，且跳出局部最优解的能力很好，容易找到全局最优解，其缺点是只能单线程作业，不能展开大范围搜索，当决策变量维度较高时，算法收敛速度很慢。

![image-20240726170514301](https://s2.loli.net/2024/07/26/rxYiEs8BlaChUzI.png)

1. **线性规划**

基本思想：线性规划（Linear programming,简称LP），是运筹学中研究较早、发展较快、应用广泛、方法较成熟的一个重要分支，是辅助人们进行科学管理的一种数学方法，是研究**线性约束条件下线性目标函数的极值同题的数学理论和方法**。

基本概念：

**决策变量**：问题中要确定的未知量用于表明规划问题中的用数量表示的方案、措施等，可由决策者决定和控制；
**目标函数**：决策变量的函数优化目标通常是求该函数的最大值或最小值；
**约束条件**：决策变量的取值所受到的约束和限制制条件，通常用含有决策变量的等式或不等式表示

表现形式：

1. 简写形式:

$$
\begin{array}{l}
\max (\text { 或 } \min ) z=\sum_{i=1}^{n} c_j x_{j}, \\
\text { s.t. } \left \{ 
	\begin{array}{l}   
		\sum_{j=1}^{n} a_{i j} x_{j} \leq(\text {或}=, \geq) b_{i}, i=1,2, \cdots, m, \\
		x_{j} \geq 0, j=1,2, \cdots, n .
	\end{array} \right. 
\end{array}
$$

2. 矩阵表现形式:

$$
\begin{array}{l}
\max (\text {或} \min ) z=c^{T} x,\\{\text { s.t. }\left\{\begin{array}{l}
A x \ \leq(\text {或}=, \geq) b, \\
x \geq 0 .
\end{array}\right.}
\end{array}
$$



$c=\left[c_{1}, c_{2}, \ldots, c_{n}\right]^{T}$——且标函数的系数向量, 即价值向量;
$x=\left[x_{1}, x_{2}, \ldots, x_{n}\right]^{T}$  ——决策向量; 
$A=\left(a_{i j}\right)_{m \times n}$ 一一约束方程组的系数矩阵; 
$b=\left[b_{1}, b_{2}, \ldots, b_{m}\right]^{T}$  一一约束方程组的常数向量。 

eg：<img src="https://s2.loli.net/2024/08/13/ADx1BKkW25HbgCT.png" alt="image-20240813191406743" style="zoom:80%;" />

2. **非线性规划**

![image-20240817231358798](D:/apps/Pictures/Typora Pictures/image-20240817231358798.png)

基本概念：模型中至少一个变量是非线性即包含$x²$， $e^x$, $sinx$， $\frac{1}{x}$, $log_2x$等形式

线性规划有通用求准确解的方法（单纯形法），它的最优解只存在于可行域的边界上；非线性规划的最优解若存在可能在其可行域的任一点达到，目前非线性规划还没有适合各种问题的一般解法，各种方法都有其特定的适用范围

基本形式：$$\begin{aligned}\ &\begin{array}{c} min\end{array} \quad f(x)\\&\text{s.t.}\begin{cases}Ax\leq b,&A_{eq}\cdot x=b_{eq}&\text{(线性)}\\c(x)\leq0,&C_{eq}(x)=0&\text{(非线性)}\\lb\leq x\leq ub\end{cases}\end{aligned}$$

3. **非线性规划——整数规划**

基本概念：规划问题中，有些最优解可能是**分数或小数**，但对于某些具体问题，常要求某些变量（全部或部分）的解必须是整数。例如，当变量代表的是机器的台数，工作的人数或装货的车数等。为了满足整数的要求，初看起来似乎只要把已得的非整数解舍入化整就可以了。实际上化整后的数不见得是可行解和最优解，所以应该有特殊的方法来求解整数规划。在整数规划中，如果所有变量都限制为整数，则称为<u>纯整数规划</u>；如果仅一部分变量限制为整数，则称为<u>混合整数规划</u>。整数规划的一种特殊情形是0-1规划，它的变数仅限于0或1

![](D:/apps/Pictures/Typora Pictures/image-20240815131450486.png)

4. **非线性规划——二次规划** （略）
5. **非线性规划——最大最小化**

```matlab
function f = Fun(x)
    a=[1 4 3 5 9 12 6 20 17 8];
    b=[2 10 8 18 1 4 5 10 8 9];
    %  函数向量
    f=zeros(10,1);
    for i = 1:10
        f(i) = abs(x(1)-a(i))+abs(x(2)-b(i));  
    end
end 

x0 = [6, 6];      % 给定初始值
lb = [3, 4];  % 决策变量的下界
ub = [8, 10];  % 决策变量的上界
[x,feval] = fminimax(@Fun,x0,[],[],[],[],lb,ub)
max(feval)
```

6. **多目标规划**（略）

